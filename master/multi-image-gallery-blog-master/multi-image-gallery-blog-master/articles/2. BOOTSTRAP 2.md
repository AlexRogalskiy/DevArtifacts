# Bootstrapping a New Project - Part 2

In my [previous article](#), I've demonstrated how to set up a Symfony project from scratch with Flex, 
create a simple set of fixtures and get the project up and running. 
Next step on our journey is populating the database with a somewhat realistic amount of data 
to test application performance. 

As a bonus, I will demonstrate how to setup simple PHPUnit test suite with basic [smoke tests](https://en.wikipedia.org/wiki/Smoke_testing_(software)).

## More Fake Data

Once your entities are polished, and you had "That's it! I'm done!" moment, it's a perfect time for 
creating a more significant dataset that can be used for further testing and preparing your app for production.

Simple fixtures as ones I've created in the previous article are great for the development phase where 
loading ~30 entities is done quickly, and it can often be repeated while changing the DB schema.

Testing app performance, simulating real-world traffic and detecting bottlenecks requires bigger dataset
(i.e., larger amoung of database entries and image files for this project). 
Generating thousands of entries takes some time (and computer resources), so I want to do it only once.

I could try to increase the `COUNT` constant in our fixture classes and see what will happen:

```
// src/DataFixtures/ORM/LoadUsersData.php
class LoadUsersData extends AbstractFixture implements ContainerAwareInterface, OrderedFixtureInterface
{
    const COUNT = 500;
    ...
}

// src/DataFixtures/ORM/LoadGalleriesData.php
class LoadGalleriesData extends AbstractFixture implements ContainerAwareInterface, OrderedFixtureInterface
{
    const COUNT = 1000;
    ...
}

```

Now, if you run `./bin/refreshDb.sh`, after some time of execution you'll probably get a not-so-nice message `PHP Fatal error:  Allowed memory size of N bytes exhausted`. 

Apart from slow execution, every error would result in an empty database because EntityManager is flushed only at the very end of the fixture class.
Additionally, Faker is downloading a random image for every gallery entry. 
For 1.000 galleries with 5 to 10 images per gallery that would be 5.000 - 10.000 downloads which is really slow.

There are excellent resources on optimizing [Doctrine](http://docs.doctrine-project.org/projects/doctrine-orm/en/latest/reference/batch-processing.html) and [Symfony](https://groups.google.com/forum/#!topic/symfony-devs/0Ez-TpsC3I0) 
for batch processing, and I'm going to use some of these tips to optimize fixtures loading.

First, I'll define a batch size of 100 galleries. 
After every batch, I'll flush and clear the `EntityManager` (i.e., detach persisted entities) and tell garbage collector to do its job.  

To track progress, I will print out some meta information (batch identifier and memory usage).

**Note:** After calling `$manager->clear()` all persisted entities are now unmanaged. 
Entity manager doesn't know about them anymore, and you'll probably get an "entity-not-persisted" error. 
The key is to merge entity back to the manager `$entity = $manager->merge($entity);`

Without the optimization, memory usage is increasing while running a `LoadGalleriesData` fixture class:
```
> loading [200] App\DataFixtures\ORM\LoadGalleriesData
100 Memory usage (currently) 24MB / (max) 24MB
200 Memory usage (currently) 26MB / (max) 26MB
300 Memory usage (currently) 28MB / (max) 28MB
400 Memory usage (currently) 30MB / (max) 30MB
500 Memory usage (currently) 32MB / (max) 32MB
600 Memory usage (currently) 34MB / (max) 34MB
700 Memory usage (currently) 36MB / (max) 36MB
800 Memory usage (currently) 38MB / (max) 38MB
900 Memory usage (currently) 40MB / (max) 40MB
1000 Memory usage (currently) 42MB / (max) 42MB
```

Memory usage starts at 24 MB and increases for 2 MB for every batch (100 galleries).
If I tried to load 100.000 galleries, I'd need 24 MB + 999 (999 batches of 100 galleries, 99900 galleries) * 2 MB = **~2 GB of memory**.

After adding `$manager->flush()` and `gc_collect_cycles()` for every batch, removing 
SQL logging with `$manager->getConnection()->getConfiguration()->setSQLLogger(null)` and
removing entity references by commenting out `$this->addReference('gallery' . $i, $gallery);`, 
memory usage became somewhat constant for every batch.

```
// Define batch size outside of the for loop
$batchSize = 100;

...

for ($i = 1; $i <= self::COUNT; $i++) {
    ...
    
    // Save the batch at the end of the for loop
    if (($i % $batchSize) == 0 || $i == self::COUNT) {
        $currentMemoryUsage = round(memory_get_usage(true) / 1024);
        $maxMemoryUsage = round(memory_get_peak_usage(true) / 1024);
        echo sprintf("%s Memory usage (currently) %dKB/ (max) %dKB \n", $i, $currentMemoryUsage, $maxMemoryUsage);
    
        $manager->flush();
        $manager->clear();
    
        // here you should merge entities you're re-using with the $manager
        // because they aren't managed anymore after calling $manager->clear();
        // e.g. if you've already loaded category or tag entities
        // $category = $manager->merge($category);
    
        gc_collect_cycles();
    }
}

```

As expected, memory usage is now stable:

```
> loading [200] App\DataFixtures\ORM\LoadGalleriesData
100 Memory usage (currently) 24MB / (max) 24MB
200 Memory usage (currently) 26MB / (max) 28MB
300 Memory usage (currently) 26MB / (max) 28MB
400 Memory usage (currently) 26MB / (max) 28MB
500 Memory usage (currently) 26MB / (max) 28MB
600 Memory usage (currently) 26MB / (max) 28MB
700 Memory usage (currently) 26MB / (max) 28MB
800 Memory usage (currently) 26MB / (max) 28MB
900 Memory usage (currently) 26MB / (max) 28MB
1000 Memory usage (currently) 26MB / (max) 28MB
```

Instead of downloading random images every time I can prepare 15 random images and update fixture script to
randomly choose one of them instead of using Faker's `$faker->image()` method. 

I'm going to take 15 images from [Unsplash](https://unsplash.com) and save them in `var/demo-data/sample-images`.
Then I will update the `LoadGalleriesData::generateRandomImage` method:

```
private function generateRandomImage($imageName)
    {
        $images = [
            'image1.jpeg',
            'image10.jpeg',
            'image11.jpeg',
            'image12.jpg',
            'image13.jpeg',
            'image14.jpeg',
            'image15.jpeg',
            'image2.jpeg',
            'image3.jpeg',
            'image4.jpeg',
            'image5.jpeg',
            'image6.jpeg',
            'image7.jpeg',
            'image8.jpeg',
            'image9.jpeg',
        ];

        $sourceDirectory = $this->container->getParameter('kernel.project_dir') . '/var/demo-data/sample-images/';
        $targetDirectory = $this->container->getParameter('kernel.project_dir') . '/var/uploads/';

        $randomImage = $images[rand(0, count($images) - 1)];
        $randomImageSourceFilePath = $sourceDirectory . $randomImage;
        $randomImageExtension = explode('.', $randomImage)[1];
        $targetImageFilename = sha1(microtime() . rand()) . '.' . $randomImageExtension;
        copy($randomImageSourceFilePath, $targetDirectory . $targetImageFilename);

        $image = new Image(
            Uuid::getFactory()->uuid4(),
            $randomImage,
            $targetImageFilename
        );

        return $image;
    }
``` 
 
It's a good idea to remove old files in `var/uploads` when reloading fixtures so I'm adding `rm var/uploads/*` command to `bin/refreshDb.sh` script,
immediately after dropping the DB schema.

Loading 500 users and 1000 galleries now takes ~7 minutes and ~28 MB of memory (peak usage).

```
Dropping database schema...
Database schema dropped successfully!
ATTENTION: This operation should not be executed in a production environment.

Creating database schema...
Database schema created successfully!
  > purging database
  > loading [100] App\DataFixtures\ORM\LoadUsersData
300 Memory usage (currently) 10MB / (max) 10MB
500 Memory usage (currently) 12MB / (max) 12MB
  > loading [200] App\DataFixtures\ORM\LoadGalleriesData
100 Memory usage (currently) 24MB / (max) 26MB
200 Memory usage (currently) 26MB / (max) 28MB
300 Memory usage (currently) 26MB / (max) 28MB
400 Memory usage (currently) 26MB / (max) 28MB
500 Memory usage (currently) 26MB / (max) 28MB
600 Memory usage (currently) 26MB / (max) 28MB
700 Memory usage (currently) 26MB / (max) 28MB
800 Memory usage (currently) 26MB / (max) 28MB
900 Memory usage (currently) 26MB / (max) 28MB
1000 Memory usage (currently) 26MB / (max) 28MB
```

## Performance

Homepage rendering became very slow, way too slow for production. 
The user can feel that app is struggling to deliver the page, probably because the app is 
rendering all galleries instead of a limited number.

Instead of rendering all galleries at once, I could update the app to render only first 12 galleries immediately and introduce lazy load.
When the user scrolls to the end of the screen, the app will fetch next 12 galleries and present them to the user.

### Performance tests
To track performance optimization, I need to establish fixed set of tests that will be used to test and benchmark 
performance improvements relatively.

I will use Siege for load testing. Here you can find more about [Siege and performance testing](https://www.sitepoint.com/web-app-performance-testing-siege-plan-test-learn/).
Instead of installing Siege on my machine I will utilize [Docker](https://www.docker.com/) - a powerful container platform. 
Simplified, Docker containers are similar to virtual machines ([but they aren't the same thing](https://www.docker.com/what-container#comparing)).
Except for building and deploying apps, Docker can be used to experiment with applications without actually installing them on your local machine.
You can build your images or use images available on [Docker Hub](https://hub.docker.com/), a public registry of Docker images.
It's especially useful when you want to experiment with different versions of the same software (e.g., different versions of PHP).

I will use [yokogawa/siege](https://hub.docker.com/r/) image to test the app.

#### Testing The Homepage

Testing the homepage is not trivial since there are AJAX requests executed
only when the user scrolls to the end of the page.

I expect all users to land on the homepage (i.e., 100%).  
I guess that 50% of them would scroll down to the end and therefore request the second page of galleries.
Furthermore, I guess that 30% of them would load the 3rd page, 
15% would request 4th page, and
5% would request 5th page.

These numbers are based on predictions, and it would be much better if I could take a
look at analytics tool and get a better insight in users' behavior, but that's impossible for a brand new app.
However, it's a good idea to take a look at analytics data now and then and adjust your test suite after the initial deploy.

I will test the homepage (and lazy load URLs) with two tests running in parallel.
First one will be testing the homepage URL only, while another one will test
lazy-load endpoint URLs.

File `lazy-load-urls.txt` contains a randomized list of lazily loaded pages URLs 
in predicted ratios:

- 10 URLs for the 2nd page (50%)
- 6 URLs for 3rd page (30%)
- 3 URLs for 4th page (15%)
- 1 URLs for 5th page (5%)

```
http://blog.app/galleries-lazy-load?page=2
http://blog.app/galleries-lazy-load?page=2
http://blog.app/galleries-lazy-load?page=2
http://blog.app/galleries-lazy-load?page=4
http://blog.app/galleries-lazy-load?page=2
http://blog.app/galleries-lazy-load?page=2
http://blog.app/galleries-lazy-load?page=3
http://blog.app/galleries-lazy-load?page=2
http://blog.app/galleries-lazy-load?page=2
http://blog.app/galleries-lazy-load?page=4
http://blog.app/galleries-lazy-load?page=2
http://blog.app/galleries-lazy-load?page=4
http://blog.app/galleries-lazy-load?page=2
http://blog.app/galleries-lazy-load?page=3
http://blog.app/galleries-lazy-load?page=3
http://blog.app/galleries-lazy-load?page=3
http://blog.app/galleries-lazy-load?page=5
http://blog.app/galleries-lazy-load?page=3
http://blog.app/galleries-lazy-load?page=2
http://blog.app/galleries-lazy-load?page=3
```

The script for testing homepage performance will run 2 Siege processes in parallel, 
one against homepage and another one against a generated list of URLs.

To execute a single HTTP request with Siege (in Docker), run:
```
docker run --rm -t yokogawa/siege -c1 -r1 blog.app
```

**Note:** If you aren't using Docker, you can omit the `docker run --rm -t yokogawa/siege` part and run Siege with the same arguments.

To run a 1-minute test with 50 concurrent users against homepage with a 1-second delay, execute:
```
docker run --rm -t yokogawa/siege -d1 -c50 -t1M http://blog.app
```

To run a 1-minute test with 50 concurrent users against URLs in `lazy-load-urls.txt`, execute:
```
docker run --rm -v `pwd`:/var/siege:ro -t yokogawa/siege -i --file=/var/siege/lazy-load-urls.txt -d1 -c50 -t1M
```
from the directory where your `lazy-load-urls.txt` is located (that directory will be mounted as a read-only volume in Docker).

Running a script `test-homepage.sh` will start 2 Siege processes (in a way suggested by this [StackOverflow answer](https://stackoverflow.com/a/5553774))
and output results from processes.

I've deployed the app on a server with Nginx and with PHP-FPM 7.1 and loaded 25.000 users and 30.000 galleries. 
Results from load testing the app homepage are: 

```
./test-homepage.sh

Transactions:		         499 hits
Availability:		      100.00 %
Elapsed time:		       59.10 secs
Data transferred:	        1.49 MB
Response time:		        4.75 secs
Transaction rate:	        8.44 trans/sec
Throughput:		        0.03 MB/sec
Concurrency:		       40.09
Successful transactions:         499
Failed transactions:	           0
Longest transaction:	       16.47
Shortest transaction:	        0.17

Transactions:		         482 hits
Availability:		      100.00 %
Elapsed time:		       59.08 secs
Data transferred:	        6.01 MB
Response time:		        4.72 secs
Transaction rate:	        8.16 trans/sec
Throughput:		        0.10 MB/sec
Concurrency:		       38.49
Successful transactions:         482
Failed transactions:	           0
Longest transaction:	       15.36
Shortest transaction:	        0.15

```

Even though app availability was 100% for both homepage and lazy-load tests, response time was ~5 seconds which
is not something we'd expect from a high performance app.


#### Testing a Single Gallery Page

Testing a single gallery page is a little bit simpler - I will run Siege against the `galleries.txt` file
where I have a list of single gallery page URLs I want to test. 
Run the command:

```
docker run --rm -v `pwd`:/var/siege:ro -t yokogawa/siege -i --file=/var/siege/galleries.txt -d1 -c50 -t1M
```
from the directory where the `galleries.txt` file is located (that directory will be mounted as a read-only volume in Docker).

Load test results for single gallery pages are somewhat better than for the homepage:  

```
./test-single-gallery.sh
** SIEGE 3.0.5
** Preparing 50 concurrent users for battle.
The server is now under siege...
Lifting the server siege...      done.

Transactions:		        3589 hits
Availability:		      100.00 %
Elapsed time:		       59.64 secs
Data transferred:	       11.15 MB
Response time:		        0.33 secs
Transaction rate:	       60.18 trans/sec
Throughput:		        0.19 MB/sec
Concurrency:		       19.62
Successful transactions:        3589
Failed transactions:	           0
Longest transaction:	        1.25
Shortest transaction:	        0.10
```

## Tests, tests, tests

To make sure I'm not breaking anything with improvements I implement in the future, I need at least some tests.
First, I'll require PHPUnit as a dev dependency:
```
composer req --dev phpunit
``` 
Then I'll create simple PHPUnit configuration by copying `phpunit.xml.dist` file created by Flex to `phpunit.xml` and
update environment variables (e.g., `DATABASE_URL` variable for the test environment).
Also, I'm adding `phpunit.xml` to `.gitignore`.

I will create basic [functional/smoke tests](https://symfony.com/doc/current/best_practices/tests.html#functional-tests) for blog homepage and single gallery pages.
These tests would only assert that URLs you provide in `SmokeTest::urlProvider()` method 
are resulting with a successful HTTP response code (i.e., HTTP status code is 2xx or 3xx).

## Stay tuned

Upcoming articles in this series will cover details about PHP and MySQL performance optimization, improving 
overall performance perception and other tips and tricks for better app performance.
